{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>더치원액1000ml</td>\n",
       "      <td>832000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>더치원액500ml</td>\n",
       "      <td>788300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>아이스더치아메리카노</td>\n",
       "      <td>572000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>더치아메리카노</td>\n",
       "      <td>244000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>더치카페라떼</td>\n",
       "      <td>36000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>아이스더치카페라떼</td>\n",
       "      <td>4500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  product_name  total_amount\n",
       "0   더치원액1000ml        832000\n",
       "1    더치원액500ml        788300\n",
       "2   아이스더치아메리카노        572000\n",
       "3      더치아메리카노        244000\n",
       "4       더치카페라떼         36000\n",
       "5    아이스더치카페라떼          4500"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from impala.dbapi import connect\n",
    "from impala.util import as_pandas\n",
    "import ast\n",
    "import math\n",
    "import redis_io as redis_io\n",
    "\n",
    "\n",
    "def get_most_popular_products(req_cate_name):\n",
    "\n",
    "    # Redis read cache value\n",
    "    #REDIS_KEY = \"product_category_info\"\n",
    "    #cached_data = redis_io.read_dict_transaction(REDIS_KEY,req_cate_name)\n",
    "\n",
    "    #if cached_data != None:\n",
    "    #    return ast.literal_eval(cached_data[0])\n",
    "\n",
    "    conn = connect(host='salest-master-server', port=21050)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('USE salest')\n",
    "\n",
    "    dict_product_cate_items = {}\n",
    "\n",
    "    # Category Items\n",
    "\n",
    "    queryStr = \"\"\"\n",
    "            SELECT DISTINCT cate_name FROM ext_menumap_info\n",
    "            \"\"\"\n",
    "\n",
    "    cur.execute(queryStr)\n",
    "    df_categories = as_pandas(cur)\n",
    "\n",
    "    dict_product_cate_items['All'] = df_categories['cate_name'].values.tolist()\n",
    "\n",
    "\n",
    "    # Most 10 papular items per each category\n",
    "\n",
    "    for cate_name in dict_product_cate_items['All']:\n",
    "        queryStr = \"\"\"\n",
    "            SELECT product_name, SUM(sales_amount) AS total_amount\n",
    "            FROM\n",
    "            (\n",
    "                SELECT cate_name,product_name,date_receipt_num,sales_amount\n",
    "                FROM \n",
    "                    (SELECT * FROM ext_menumap_info WHERE cate_name = '\"\"\" + cate_name + \"\"\"' ) view_specific_menu JOIN ext_tr_receipt USING (product_code)\n",
    "            ) view_tr_specific_cate_menu\n",
    "            GROUP BY (view_tr_specific_cate_menu.product_name)\n",
    "            ORDER BY (SUM(sales_amount)) DESC\n",
    "            LIMIT 10\n",
    "            \"\"\"\n",
    "    cur.execute(queryStr)\n",
    "    \n",
    "    df_papular_products = as_pandas(cur)\n",
    "    conn.close()\n",
    "    \n",
    "    return df_papular_products\n",
    "\n",
    "    df_papular_products = df_papular_products[df_papular_products.total_amount != 0]\n",
    "    dict_product_cate_items[cate_name] = df_papular_products['product_name'].values.tolist()\n",
    "\n",
    "    # Redis save cache value\n",
    "    #redis_io.write_dict_transaction(REDIS_KEY, dict_product_cate_items, 60*60*24)\n",
    "    #\n",
    "    return dict_product_cate_items[req_cate_name]\n",
    "\n",
    "result_list = get_most_popular_products('All')\n",
    "result_list\n",
    "#for i in result_list:\n",
    "#    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'price': '2500', 'product_code': '4'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from impala.dbapi import connect\n",
    "from impala.util import as_pandas\n",
    "import ast\n",
    "import math\n",
    "import redis_io as redis_io\n",
    "\n",
    "\n",
    "def get_product_data(product_name):\n",
    "    \n",
    "    # Redis read cache value\n",
    "    REDIS_KEY_PREFIX = \"popular_product_info\"\n",
    "    \n",
    "    def get_cach_value(product_name):\n",
    "        cache_data = redis_io.read_dict_transaction(REDIS_KEY_PREFIX + \":\" + product_name, ['product_code','price'])\n",
    "        if cache_data == None:\n",
    "            return None\n",
    "    \n",
    "        dict_data = {}\n",
    "        dict_data['product_code'] = cache_data[0]\n",
    "        dict_data['price'] = cache_data[1]\n",
    "        return dict_data\n",
    "    \n",
    "\n",
    "    cached_data = get_cach_value(product_name)\n",
    "    if cached_data != None:\n",
    "        return cached_data\n",
    "    \n",
    "    conn = connect(host='salest-master-server', port=21050)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('USE salest')\n",
    "  \n",
    "    queryStr = \"\"\"SELECT product_name,price,product_code FROM ext_menumap_info\"\"\"\n",
    "    \n",
    "    cur.execute(queryStr)\n",
    "    df_categories = as_pandas(cur)\n",
    "\n",
    "    df_categories = df_categories[df_categories.price != 0]\n",
    "    #df_categories.set_index('product_name', inplace=True)\n",
    "    \n",
    "    for idx,row in df_categories.iterrows():\n",
    "        key = \"{0}:{1}\".format(REDIS_KEY_PREFIX,row.product_name)\n",
    "        value = row[['product_code','price']].to_dict()\n",
    "        redis_io.write_dict_transaction(key, value, 60*60)\n",
    "        \n",
    "    cached_data = redis_io.read_dict_transaction(REDIS_KEY_PREFIX + \":\" + product_name, ['product_code','price'])\n",
    "    return get_cach_value(product_name)\n",
    "\n",
    "\n",
    "get_product_data('아메리카노')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from impala.dbapi import connect\n",
    "from impala.util import as_pandas\n",
    "import ast\n",
    "import math\n",
    "import redis_io as redis_io\n",
    "\n",
    "redis_io.get_transaction_incr_counter(\"2016-05-07\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'10': 0,\n",
       " '11': 0,\n",
       " '12': 0,\n",
       " '13': 10600,\n",
       " '14': 15700,\n",
       " '15': 5000,\n",
       " '16': 13100,\n",
       " '17': 7500,\n",
       " '18': 9000,\n",
       " '19': 26800,\n",
       " '20': 0,\n",
       " '21': 5000,\n",
       " '22': 13200,\n",
       " '23': 0,\n",
       " 'date': '2015-05-11'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from impala.dbapi import connect\n",
    "from impala.util import as_pandas\n",
    "import ast\n",
    "import math\n",
    "import redis_io as redis_io\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "from dateutil.parser import parse\n",
    "import numpy as np\n",
    "\n",
    "def get_past_target_date(date_year_mon_day):\n",
    "    \n",
    "    day_of_week_map = ['MON', 'TUE', 'WED', 'THU', 'FRI', 'SAT', 'SUN']\n",
    "\n",
    "    date_val = parse(date_year_mon_day)\n",
    "\n",
    "    last_day_of_month = (date_val + MonthEnd()).day\n",
    "    week_number = (date_val.day - 1) // 7 + 1\n",
    "    \n",
    "    freq_faram = \"WOM-{0}{1}\".format(week_number, day_of_week_map[date_val.weekday()])\n",
    "\n",
    "    last_year_day_start = \"{0}-{1}-01\".format(date_val.year-1, date_val.month)\n",
    "    last_year_day_end =  \"{0}-{1}-{2}\".format(date_val.year-1, date_val.month, last_day_of_month)\n",
    "\n",
    "    target_date_idx = pd.date_range(last_year_day_start, last_year_day_end, freq=freq_faram)\n",
    "\n",
    "    date_list = target_date_idx.strftime('%Y-%m-%d').tolist()\n",
    "    return date_list\n",
    "\n",
    "\n",
    "def get_timebase_data_on_past_specific_date(cur_date):\n",
    "    \n",
    "    # Redis read cache value\n",
    "    REDIS_KEY_PREFIX = \"past_timebase_data_of\"\n",
    "    \n",
    "    def get_cach_value(cur_date):\n",
    "        cache_data = redis_io.read_dict_transaction(REDIS_KEY_PREFIX + \":\" + cur_date)\n",
    "        if cache_data == None:\n",
    "            return None\n",
    "        print cache_data\n",
    "        \n",
    "    #cached_data = get_cach_value(cur_date)\n",
    "    #if cached_data != None:\n",
    "    #    return cached_data\n",
    "    \n",
    "    \n",
    "    conn = connect(host='salest-master-server', port=21050)\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    cur.execute('USE salest')\n",
    "    \n",
    "    date_list = tuple(get_past_target_date(cur_date))\n",
    "\n",
    "    cur.execute(\n",
    "    \"\"\"\n",
    "        SELECT time_hour, CAST(SUM(sales_amount) as INTEGER) AS total_amount, \n",
    "        COUNT(sales_amount) as num_of_transaction,\n",
    "        COUNT(DISTINCT year_month_day) as date_count\n",
    "        FROM(\n",
    "            SELECT SUBSTR(date_receipt_num,1,10) AS year_month_day,\n",
    "            SUBSTR(tr_time,1,2) AS time_hour,\n",
    "            sales_amount\n",
    "            FROM ext_tr_receipt WHERE SUBSTR(date_receipt_num,1,10) IN ('%s')\n",
    "            \"\"\" % date_list +\n",
    "            \"\"\"\n",
    "        ) view_tr_total_amount_by_dayofweek\n",
    "        GROUP BY time_hour ORDER BY time_hour ASC\n",
    "        \"\"\"\n",
    "    )\n",
    "    df_by_hour = as_pandas(cur)\n",
    "    conn.close()\n",
    "    \n",
    "    df_by_hour.set_index('time_hour',inplace=True)\n",
    "    df_by_hour = df_by_hour.reindex([[str(i) for i in np.arange(10,24)]],fill_value=0)\n",
    "\n",
    "    dict_result = df_by_hour['total_amount'].to_dict()\n",
    "    dict_result['date'] = date_list[0]\n",
    "     \n",
    "    #redis_io.write_dict_transaction(REDIS_KEY_PREFIX + \":\" + cur_date, dict_result, 60*60)\n",
    "        \n",
    "    return dict_result\n",
    "\n",
    "df_test = get_timebase_data_on_past_specific_date(\"2016-05-09\")\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'10': '0',\n",
       " '11': '0',\n",
       " '12': '0',\n",
       " '13': '10600',\n",
       " '14': '15700',\n",
       " '15': '5000',\n",
       " '16': '13100',\n",
       " '17': '7500',\n",
       " '18': '9000',\n",
       " '19': '26800',\n",
       " '20': '0',\n",
       " '21': '5000',\n",
       " '22': '13200',\n",
       " '23': '0',\n",
       " 'date': '2015-05-11'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import redis_io as redis_io\n",
    "\n",
    "REDIS_KEY_PREFIX = \"past_timebase_data_of\"\n",
    "\n",
    "redis_io.read_dict_transaction(REDIS_KEY_PREFIX + \":\" + \"2016-05-09\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10: '0',\n",
       " 11: '0',\n",
       " 12: '0',\n",
       " 13: '36500',\n",
       " 14: '85900',\n",
       " 15: '0',\n",
       " 16: '0',\n",
       " 17: '0',\n",
       " 18: '0',\n",
       " 19: '0',\n",
       " 20: '103200',\n",
       " 21: '101900',\n",
       " 22: '204600',\n",
       " 23: '0'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import redis_io as redis_io\n",
    "import numpy as np\n",
    "\n",
    "def get_timebase_data_on_today_specific_date(cur_date):\n",
    "    \n",
    "    # Redis read cache value\n",
    "    REDIS_KEY_PREFIX = \"today_timebase_data_of\"\n",
    "    \n",
    "    dictData = {}\n",
    "    \n",
    "    for time_idx in np.arange(10,24):\n",
    "        cache_value = redis_io.read_transaction(\"{0}:{1}:{2}\".format(REDIS_KEY_PREFIX,cur_date,time_idx))\n",
    "        if cache_value != None:\n",
    "            dictData[time_idx] = str(cache_value)\n",
    "        else:\n",
    "            dictData[time_idx] = str(0)\n",
    "        \n",
    "    return dictData\n",
    "\n",
    "get_timebase_data_on_today_specific_date(\"2016-05-09\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'10': '0',\n",
       " '11': '0',\n",
       " '12': '3800',\n",
       " '13': '28900',\n",
       " '14': '50600',\n",
       " '15': '28800',\n",
       " '16': '29600',\n",
       " '17': '25000',\n",
       " '18': '24000',\n",
       " '19': '7100',\n",
       " '20': '12200',\n",
       " '21': '25700',\n",
       " '22': '14400',\n",
       " '23': '0',\n",
       " 'date': '2015-05-12'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from impala.dbapi import connect\n",
    "from impala.util import as_pandas\n",
    "import ast\n",
    "import math\n",
    "import redis_io as redis_io\n",
    "\n",
    "def get_timebase_data_on_past_specific_date(cur_date):\n",
    "    \n",
    "    # Redis read cache value\n",
    "    REDIS_KEY_PREFIX = \"past_timebase_data_of\"\n",
    "    \n",
    "    def get_cach_value(cur_date):\n",
    "        return redis_io.read_dict_transaction(REDIS_KEY_PREFIX + \":\" + cur_date) \n",
    "    \n",
    "    cached_data = get_cach_value(cur_date)\n",
    "    if cached_data != None:\n",
    "        return cached_data\n",
    "    \n",
    "    \n",
    "    conn = connect(host='salest-master-server', port=21050)\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    cur.execute('USE salest')\n",
    "    \n",
    "    date_list = tuple(get_past_target_date(cur_date))\n",
    "\n",
    "    cur.execute(\n",
    "    \"\"\"\n",
    "        SELECT time_hour, CAST(SUM(sales_amount) as INTEGER) AS total_amount, \n",
    "        COUNT(sales_amount) as num_of_transaction,\n",
    "        COUNT(DISTINCT year_month_day) as date_count\n",
    "        FROM(\n",
    "            SELECT SUBSTR(date_receipt_num,1,10) AS year_month_day,\n",
    "            SUBSTR(tr_time,1,2) AS time_hour,\n",
    "            sales_amount\n",
    "            FROM ext_tr_receipt WHERE SUBSTR(date_receipt_num,1,10) IN ('%s')\n",
    "            \"\"\" % date_list +\n",
    "            \"\"\"\n",
    "        ) view_tr_total_amount_by_dayofweek\n",
    "        GROUP BY time_hour ORDER BY time_hour ASC\n",
    "        \"\"\"\n",
    "    )\n",
    "    df_by_hour = as_pandas(cur)\n",
    "    conn.close()\n",
    "    \n",
    "    df_by_hour.set_index('time_hour',inplace=True)\n",
    "    df_by_hour = df_by_hour.reindex([[str(i) for i in np.arange(10,24)]],fill_value=0)\n",
    "\n",
    "    dict_result = df_by_hour['total_amount'].to_dict()\n",
    "    dict_result['date'] = date_list[0]\n",
    "     \n",
    "    redis_io.write_dict_transaction(REDIS_KEY_PREFIX + \":\" + cur_date, dict_result, 60*60)\n",
    "    \n",
    "    ret_dict = get_cach_value(cur_date)\n",
    "\n",
    "    return ret_dict\n",
    "\n",
    "get_timebase_data_on_past_specific_date(\"2016-05-10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
